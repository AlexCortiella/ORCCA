{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3033ebde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import random_split, DataLoader, Dataset\n",
    "\n",
    "# Note - you must have torchvision installed for this example\n",
    "from torchvision import transforms\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "from torchvision.io import read_image\n",
    "import torchvision\n",
    "import json\n",
    "import matplotlib.animation as animation\n",
    "from matplotlib.patches import Ellipse\n",
    "# import matplotlib.transforms as transforms\n",
    "import shutil\n",
    "\n",
    "from data import KaggleDataset, KaggleDataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64d3074a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, encoded_space_dim=2, fc2_input_dim=128, num_channels=[8, 16, 32], in_chan = 3):\n",
    "        super().__init__()\n",
    "        self.encoded_space_dim = encoded_space_dim\n",
    "        self.num_channels = num_channels\n",
    "\n",
    "        ### Convolutional section\n",
    "        self.compress_layer = nn.Conv2d(3, 3, 3, stride=2, padding=0)\n",
    "\n",
    "        self.encoder_cnn = nn.Sequential(\n",
    "            nn.Conv2d(3, self.num_channels[0], 3, stride=2, padding=0),\n",
    "            nn.BatchNorm2d(self.num_channels[0]),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(self.num_channels[0], self.num_channels[1], 3, stride=2, padding=0),\n",
    "            nn.BatchNorm2d(self.num_channels[1]),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(self.num_channels[1], self.num_channels[2], 3, stride=2, padding=0),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        ### Flatten layer\n",
    "        self.flatten = nn.Flatten(start_dim=1)\n",
    "        ### Linear section\n",
    "        self.encoder_lin = nn.Sequential(\n",
    "            nn.Linear(9 * 9 * self.num_channels[2], fc2_input_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(fc2_input_dim, encoded_space_dim * 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        for _ in range(3):\n",
    "            x = self.compress_layer(x)\n",
    "        x = self.encoder_cnn(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.encoder_lin(x)\n",
    "        mu, logsigmasq = x[:, :self.encoded_space_dim], x[:, self.encoded_space_dim:]\n",
    "        return mu, logsigmasq\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "\n",
    "    def __init__(self, encoded_space_dim=2, fc2_input_dim=128, num_channels=[32, 16, 8], in_chan = 3):\n",
    "        super().__init__()\n",
    "        self.decoder_lin = nn.Sequential(\n",
    "            nn.Linear(encoded_space_dim, fc2_input_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(fc2_input_dim, 9 * 9 * num_channels[0]),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.unflatten = nn.Unflatten(dim=1,\n",
    "                                      unflattened_size=(num_channels[0], 9, 9))\n",
    "\n",
    "        self.decoder_conv = nn.Sequential(\n",
    "            nn.ConvTranspose2d(num_channels[0], num_channels[1], 3,\n",
    "                               stride=2, output_padding=(0, 0)),\n",
    "            nn.BatchNorm2d(num_channels[1]),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(num_channels[1], num_channels[2], 3, stride=2,\n",
    "                               padding=0, output_padding=(0, 0)),\n",
    "            nn.BatchNorm2d(num_channels[2]),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(num_channels[2], 2*in_chan, 3, stride=2,\n",
    "                               padding=0, output_padding=(0, 0))\n",
    "        )\n",
    "\n",
    "\n",
    "        self.decompress_layer_0 = nn.ConvTranspose2d(2*in_chan, 2*in_chan, 3, stride=2, padding=0, output_padding=(0,0))\n",
    "        self.decompress_layer_1 = nn.ConvTranspose2d(2*in_chan, 2*in_chan, 3, stride=2, padding=0, output_padding=(1,1))\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.decoder_lin(x)\n",
    "        x = self.unflatten(x)\n",
    "        x = self.decoder_conv(x)\n",
    "#         x = self.decompress_layer_0(x)\n",
    "        for _ in range(2):\n",
    "            x = self.decompress_layer_0(x)\n",
    "        x = self.decompress_layer_1(x)\n",
    "        mu, logsigmasq = x[:, :3, :, :], x[:, 3:, :, :]\n",
    "        return mu, logsigmasq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f89119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File corrupted - dog_9931.jpg - Train. Ignoring file...\n",
      "File corrupted - dog_9955.jpg - Train. Ignoring file...\n",
      "File corrupted - dog_997.jpg - Train. Ignoring file...\n",
      "File corrupted - dog_9940.jpg - Train. Ignoring file...\n",
      "File corrupted - dog_9987.jpg - Train. Ignoring file...\n",
      "File corrupted - dog_9995.jpg - Train. Ignoring file...\n",
      "File corrupted - dog_9972.jpg - Train. Ignoring file...\n",
      "File corrupted - dog_9997.jpg - Train. Ignoring file...\n",
      "File corrupted - dog_9968.jpg - Train. Ignoring file...\n",
      "File corrupted - dog_9988.jpg - Train. Ignoring file...\n",
      "File corrupted - dog_9956.jpg - Train. Ignoring file...\n",
      "File corrupted - dog_995.jpg - Train. Ignoring file...\n",
      "File corrupted - dog_9994.jpg - Train. Ignoring file...\n",
      "File corrupted - dog_9948.jpg - Train. Ignoring file...\n",
      "File corrupted - dog_9950.jpg - Train. Ignoring file...\n",
      "File corrupted - dog_9954.jpg - Train. Ignoring file...\n",
      "File corrupted - dog_9976.jpg - Train. Ignoring file...\n",
      "File corrupted - dog_9967.jpg - Train. Ignoring file...\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Normal\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "r = 202211010\n",
    "np.random.seed(r)\n",
    "torch.manual_seed(r)\n",
    "\n",
    "D = 1 # number of modalities\n",
    "dim = 64 # dimension of each modality (assume to be same)\n",
    "K = 2\n",
    "Z = 2\n",
    "latent_dim = Z\n",
    "\n",
    "lr = 0.5*1e-3\n",
    "num_epochs = 50\n",
    "batch_size = 8\n",
    "num_workers = 8\n",
    "em_reg = 1e-6\n",
    "logsigmasq_reg = em_reg\n",
    "\n",
    "means_hist = []\n",
    "mu_c_hist = []\n",
    "logsigmasq_c_hist = []\n",
    "gamma_c_train_hist = []\n",
    "gamma_c_val_hist = []\n",
    "\n",
    "\n",
    "w_rec = 1.0\n",
    "w_reg = 1.0\n",
    "w_entr = 1.0\n",
    "\n",
    "\n",
    "sim_name = F'gmvae_ld{latent_dim}_nc{K}_rec{w_rec}_reg{w_reg}_entr{w_entr}'\n",
    "data_dir = './data/kaggle_cats_and_dogs/PetImages'\n",
    "\n",
    "my_datamodule = KaggleDataModule(data_dir, 640, n_train = 5000, n_valid = 1000, n_test = 100, batch_size = 8)\n",
    "my_datamodule.setup('fit')\n",
    "\n",
    "save_every = 1\n",
    "\n",
    "# N_train, W_img, H_img = train_dataset.data.shape  # 60000, 28, 28\n",
    "# N_test, _, _ = test_dataset.data.shape  # 10000, 28, 28\n",
    "\n",
    "train_loader = my_datamodule.train_dataloader()\n",
    "valid_loader = my_datamodule.valid_dataloader()\n",
    "\n",
    "train_labels = torch.Tensor([int(train_loader.dataset[i][1]) for i in range(len(train_loader.dataset))])\n",
    "valid_labels = torch.Tensor([int(valid_loader.dataset[i][1]) for i in range(len(valid_loader.dataset))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfa33c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Normal\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "# from kmeans_pytorch import kmeans\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def encoder_step(x, encoder, decoder):\n",
    "    \"\"\" Computes a stochastic estimate of the rescaled evidence lower bound\n",
    "\n",
    "    Args:\n",
    "        x_list: length-D list of (N, data_dim) torch.tensor\n",
    "        encoder_list: length-D list of Encoder\n",
    "        decoder_list: length-D list of Decoder\n",
    "        params: dictionary of other parameters\n",
    "    Returns:\n",
    "        elbo: a (,) torch.tensor containing the estimate of the ELBO\n",
    "    \"\"\"\n",
    "    mu, logsigmasq = encoder.forward(x)\n",
    "    return mu, logsigmasq + logsigmasq_reg\n",
    "\n",
    "def em_step(z, mu, params, update_by_batch=False):\n",
    "\n",
    "    mu_c = params['mu_c'].to(device)  # (K, Z)\n",
    "    logsigmasq_c = params['logsigmasq_c'].to(device)  # (K, Z)\n",
    "    sigma_c = torch.exp(0.5 * logsigmasq_c)\n",
    "    pi_c = params['pi_c'].to(device)\n",
    "\n",
    "    log_prob_zc = Normal(mu_c, sigma_c).log_prob(z.unsqueeze(dim=1)).sum(dim=2) + torch.log(pi_c)  #[N, K]\n",
    "    log_prob_zc -= log_prob_zc.logsumexp(dim=1, keepdims=True)\n",
    "    gamma_c = torch.exp(log_prob_zc) + em_reg\n",
    "\n",
    "    denominator = torch.sum(gamma_c, dim=0).unsqueeze(1)\n",
    "    mu_c = torch.einsum('nc,nz->cz', gamma_c, mu) / denominator\n",
    "    logsigmasq_c = torch.log(torch.einsum('nc,ncz->cz', gamma_c, (mu.unsqueeze(dim=1) - mu_c) ** 2)) - torch.log(denominator)\n",
    "\n",
    "    if not update_by_batch:\n",
    "        return gamma_c, mu_c, logsigmasq_c\n",
    "\n",
    "    else:\n",
    "        hist_weights = params['hist_weights'].to(device)\n",
    "        hist_mu_c = params['hist_mu_c'].to(device)\n",
    "        hist_logsigmasq_c = params['hist_logsigmasq_c'].to(device)\n",
    "\n",
    "        curr_weights = denominator\n",
    "        new_weights = hist_weights + curr_weights\n",
    "        new_mu_c = (hist_weights * hist_mu_c + curr_weights * mu_c) / new_weights\n",
    "        new_logsigmasq_c = torch.log(hist_weights * torch.exp(hist_logsigmasq_c) + curr_weights * torch.exp(logsigmasq_c)) - torch.log(new_weights)\n",
    "        # new_logsigmasq_c = torch.log(torch.exp(torch.log(hist_weights) + hist_logsigmasq_c) +\n",
    "        #                              torch.exp(torch.log(curr_weights) + logsigmasq_c)) - torch.log(new_weights)\n",
    "\n",
    "        params['hist_weights'] = new_weights\n",
    "        params['hist_mu_c'] = new_mu_c\n",
    "        params['hist_logsigmasq_c'] = new_logsigmasq_c\n",
    "        return gamma_c, new_mu_c, new_logsigmasq_c\n",
    "\n",
    "\n",
    "def decoder_step(x, z, encoder, decoder, params, mu, logsigmasq, gamma_c):\n",
    "    \"\"\"\n",
    "    Computes a stochastic estimate of the ELBO.\n",
    "    :param x_list: length-D list of (N, data_dim) torch.tensor\n",
    "    :param z: MC samples of the encoded distributions\n",
    "    :param encoder_list: length-D list of Encoder\n",
    "    :param decoder_list: length-D list of Decoder\n",
    "    :param params: dictionary of non-DNN parameters\n",
    "    :return:\n",
    "        elbo: (,) tensor containing the elbo estimation\n",
    "    \"\"\"\n",
    "    sigma = torch.exp(0.5 * logsigmasq)\n",
    "    mu_c = params['mu_c']\n",
    "    logsigmasq_c = params['logsigmasq_c']\n",
    "    pi_c = params['pi_c']\n",
    "\n",
    "    elbo = 0\n",
    "    \n",
    "    reconstruction = 0\n",
    "    regularization = 0\n",
    "    entropy = 0\n",
    "    \n",
    "    mu_, logsigmasq_ = decoder.forward(z)\n",
    "    reconstruction += Normal(mu_, torch.exp(0.5 * logsigmasq_)).log_prob(x).sum()\n",
    "        \n",
    "    regularization = - 0.5 * torch.sum(gamma_c * (logsigmasq_c + (sigma.unsqueeze(1) ** 2 + (mu.unsqueeze(1) - mu_c) ** 2) /\n",
    "                                         torch.exp(logsigmasq_c)).sum(dim=2))\n",
    "    \n",
    "    entropy = torch.sum(gamma_c * (torch.log(pi_c) - torch.log(gamma_c))) + 0.5 * torch.sum(1 + logsigmasq)\n",
    "\n",
    "    elbo = w_rec*reconstruction + w_reg*regularization + w_entr*entropy\n",
    "    \n",
    "    return elbo, reconstruction, regularization, entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1871b934",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# initialize latent GMM model parameters\n",
    "params = {}\n",
    "device = 0\n",
    "\n",
    "pi_variables = torch.zeros(K, requires_grad = True, device = device)\n",
    "params['pi_c'] = torch.ones(K) / K\n",
    "torch.manual_seed(r)\n",
    "params['mu_c'] = torch.rand((K, Z)) * 2.0 - 1.0\n",
    "params['mu_c'] = params['mu_c']\n",
    "params['logsigmasq_c'] = torch.zeros((K, Z))\n",
    "\n",
    "# initialize neural networks\n",
    "encoder_list = []\n",
    "decoder_list = []\n",
    "trainable_parameters = []\n",
    "trainable_parameters.append(pi_variables)\n",
    "\n",
    "torch.manual_seed(r)\n",
    "encoder = Encoder(encoded_space_dim = latent_dim).to(device)\n",
    "decoder = Decoder(encoded_space_dim = latent_dim).to(device)\n",
    "\n",
    "trainable_parameters += list(encoder.parameters()) + list(decoder.parameters())\n",
    "\n",
    "optimizer = optim.Adam(trainable_parameters, lr=lr)\n",
    "\n",
    "\n",
    "# training\n",
    "train_loss = torch.zeros(num_epochs)\n",
    "rec_loss = torch.zeros(num_epochs)\n",
    "reg_loss = torch.zeros(num_epochs)\n",
    "entr_loss = torch.zeros(num_epochs)\n",
    "\n",
    "valid_loss = torch.zeros(num_epochs)\n",
    "pi_history = torch.zeros((num_epochs, K))\n",
    "min_valid_loss = torch.inf\n",
    "epoch_list = []\n",
    "train_loss_list = []\n",
    "valid_loss_list = []\n",
    "\n",
    "rec_loss_list = []\n",
    "reg_loss_list = []\n",
    "entr_loss_list = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "\n",
    "    train_elbo = 0\n",
    "    rec_elbo = 0\n",
    "    reg_elbo = 0\n",
    "    entr_elbo = 0\n",
    "    gamma_c_epoch = []\n",
    "    params['hist_weights'] = torch.zeros((K, 1)).clone().detach()\n",
    "    params['hist_mu_c'] = torch.zeros((K, Z)).clone().detach()\n",
    "    params['hist_logsigmasq_c'] = torch.zeros((K, Z)).clone().detach()\n",
    "\n",
    "    for (batch_idx, batch_x) in enumerate(train_loader):\n",
    "        \n",
    "        x = batch_x[0].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        pi_c = torch.exp(pi_variables) / torch.sum(torch.exp(pi_variables))\n",
    "#         print(f'pi variables: {pi_variables}')\n",
    "#         print(f'pi_c: {pi_c}')\n",
    "\n",
    "        params['pi_c'] = pi_c\n",
    "\n",
    "        mu, logsigmasq = encoder_step(x, encoder, decoder)\n",
    "#         print(f'mu: {mu}')\n",
    "#         print(f'logsigmasq: {logsigmasq}')\n",
    "        sigma = torch.exp(0.5 * logsigmasq)\n",
    "        torch.manual_seed(r)\n",
    "        eps = Normal(0, 1).sample(mu.shape).to(device)\n",
    "        z = mu + eps * sigma\n",
    "#         print(f'z: {z}')\n",
    "\n",
    "        with torch.no_grad():\n",
    "            gamma_c, mu_c, logsigmasq_c = em_step(z, mu, params, update_by_batch=True)\n",
    "            \n",
    "#         print(f'gamma_c: {gamma_c}')\n",
    "#         print(f'mu_c: {mu_c}')\n",
    "#         print(f'logsigmasq_c: {logsigmasq_c}')\n",
    "        params['mu_c'] = mu_c\n",
    "        params['logsigmasq_c'] = logsigmasq_c\n",
    "        gamma_c_epoch.append(gamma_c)\n",
    "\n",
    "        elbo, rec, reg, entr = decoder_step(x, z, encoder, decoder, params, mu, logsigmasq, gamma_c)\n",
    "        \n",
    "        train_elbo += elbo.item()\n",
    "        rec_elbo += rec.item()\n",
    "        reg_elbo += reg.item()\n",
    "        entr_elbo += entr.item()\n",
    "        loss = - elbo\n",
    "        \n",
    "#         print(f'step: {batch_idx} | train_loss: {-train_elbo}')\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    gamma_c_train_hist.append(torch.vstack(gamma_c_epoch))\n",
    "\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "\n",
    "    valid_elbo = 0\n",
    "    gamma_c_epoch = []\n",
    "    with torch.no_grad():\n",
    "        for (batch_idx, batch_x) in enumerate(valid_loader):\n",
    "#             print('VALIDATION')\n",
    "            x = batch_x[0].to(device)\n",
    "            mu, logsigmasq = encoder_step(x, encoder, decoder)\n",
    "#             print(f'mu: {mu}')\n",
    "#             print(f'logsigmasq: {logsigmasq}')\n",
    "            sigma = torch.exp(0.5 * logsigmasq)\n",
    "            torch.manual_seed(r)\n",
    "            eps = Normal(0, 1).sample(mu.shape).to(device)\n",
    "            z = mu + eps * sigma\n",
    "#             print(f'z: {z}')\n",
    "            with torch.no_grad():\n",
    "                gamma_c, _, _ = em_step(z, mu, params)\n",
    "#             print(f'gamma_c: {gamma_c}')\n",
    "            gamma_c_epoch.append(gamma_c)\n",
    "            elbo, rec, reg, entr  = decoder_step(x, z, encoder, decoder, params, mu, logsigmasq, gamma_c)\n",
    "            valid_elbo += elbo.item()\n",
    "            \n",
    "    gamma_c_val_hist.append(torch.vstack(gamma_c_epoch))\n",
    "\n",
    "    train_elbo /= len(train_loader.dataset)\n",
    "    valid_elbo /= len(valid_loader.dataset)\n",
    "    # print('====> Epoch: {} Train ELBO: {:.4f} '.format(epoch, train_elbo))\n",
    "    print('====> Epoch: {} Train ELBO: {:.4f} Val ELBO: {:.4f}'.format(epoch, train_elbo, valid_elbo))\n",
    "\n",
    "    train_loss[epoch] = - train_elbo\n",
    "    rec_loss[epoch] = - rec_elbo\n",
    "    reg_loss[epoch] = - reg_elbo\n",
    "    entr_loss[epoch] = - entr_elbo\n",
    "    valid_loss[epoch] = - valid_elbo\n",
    "    pi_history[epoch] = params['pi_c']\n",
    "\n",
    "    if epoch % save_every == 0:\n",
    "        epoch_list.append(epoch)\n",
    "        train_loss_list.append(train_loss[epoch].item())\n",
    "        valid_loss_list.append(valid_loss[epoch].item())\n",
    "        rec_loss_list.append(rec_loss[epoch].item())\n",
    "        reg_loss_list.append(reg_loss[epoch].item())\n",
    "        entr_loss_list.append(entr_loss[epoch].item())\n",
    "        # Plot the first two dimensions of the latents\n",
    "        with torch.no_grad():\n",
    "            means = []\n",
    "            # labels = []\n",
    "            for batch_x in train_loader:\n",
    "                x = batch_x[0].to(device)\n",
    "                mean, _ = encoder_step(x, encoder, decoder)\n",
    "                means.append(mean)\n",
    "                \n",
    "                # labels.append(batch_label)\n",
    "\n",
    "        means = torch.vstack(means).cpu()\n",
    "        # labels = torch.hstack(labels)\n",
    "        means_hist.append(means)\n",
    "        mu_c_hist.append(params['mu_c'].cpu())\n",
    "        logsigmasq_c_hist.append(params['logsigmasq_c'].cpu())\n",
    "        fig, ax = plt.subplots(figsize=(6, 5))\n",
    "        for i in range(K):\n",
    "            means_i = means[train_labels == i]\n",
    "            ax.scatter(means_i[:, 0], means_i[:, 1], alpha=0.25, label=str(i))\n",
    "        for i in range(K):\n",
    "            ax.plot(params['mu_c'].cpu()[i, 0], params['mu_c'].cpu()[i, 1], 'x', markersize=12) #, label='$\\mu$' + str(i + 1))\n",
    "        \n",
    "        ax.set_xlabel('$z_1$')\n",
    "        ax.set_ylabel('$z_2$')\n",
    "        ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "        fig.tight_layout()\n",
    "        plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6bd15b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = f'./results/{sim_name}/'\n",
    "#plt.plot(train_e)\n",
    "if os.path.exists(path):\n",
    "    shutil.rmtree(path)\n",
    "os.makedirs(path)\n",
    "\n",
    "# Compute the mean of the latents given the data\n",
    "encoder.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    means = []\n",
    "    # labels = []\n",
    "    for batch_x in train_loader:\n",
    "        x = batch_x[0].to(device)\n",
    "        mean, _ = encoder_step(x, encoder, decoder)\n",
    "        means.append(mean)\n",
    "        # labels.append(batch_label)\n",
    "\n",
    "means = torch.vstack(means)\n",
    "# labels = torch.hstack(labels)\n",
    "\n",
    "with torch.no_grad():\n",
    "    gamma_c, mu_c, logsigmasq_c = em_step(means, means, params, update_by_batch=False)\n",
    "\n",
    "my_datamodule.setup('test')\n",
    "test_loader = my_datamodule.test_dataloader()\n",
    "with torch.no_grad():\n",
    "    means_test = []\n",
    "    for batch_x in test_loader:\n",
    "        x = batch_x[0].to(device)\n",
    "        mean, _ = encoder_step(x, encoder, decoder)\n",
    "        means_test.append(mean)\n",
    "        # labels.append(batch_label)\n",
    "means_test = torch.cat(means_test)\n",
    "\n",
    "# my_datamodule.setup('outliers')\n",
    "# outliers_loader = my_datamodule.outliers_dataloader()\n",
    "# with torch.no_grad():\n",
    "#     means_outliers = []\n",
    "#     for batch_x in outliers_loader:\n",
    "#         x = batch_x[0].to(device)\n",
    "#         mean, _ = encoder_step(x, encoder, decoder)\n",
    "#         means_outliers.append(mean)\n",
    "#         # labels.append(batch_label)\n",
    "# means_outliers = torch.cat(means_outliers)\n",
    "\n",
    "# Plot the first two dimensions of the latents\n",
    "# plot_params()\n",
    "fig, ax = plt.subplots(figsize=(6, 5))\n",
    "cluster_means = torch.zeros((K, Z))\n",
    "for i in range(K):\n",
    "    means_i = means[train_labels == i].cpu()\n",
    "    ax.scatter(means_i[:, 0], means_i[:, 1], alpha=0.25, label=str(i))\n",
    "    cluster_means[i] = torch.mean(means_i, dim=0)\n",
    "for i in range(K):\n",
    "    ax.plot(params['mu_c'].cpu()[i, 0], params['mu_c'].cpu()[i, 1], 'x', markersize=12, color = 'k')  # , label='$\\mu$' + str(i + 1))\n",
    "\n",
    "ax.scatter(means_test[:, 0].cpu(), means_test[:, 1].cpu(), alpha=1, color = 'g')\n",
    "# ax.scatter(means_outliers[:, 0].cpu(), means_outliers[:, 1].cpu(), alpha=1, color = 'r')\n",
    "ax.set_xlabel('$z_1$ mean')\n",
    "ax.set_ylabel('$z_2$ mean')\n",
    "ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "fig.tight_layout()\n",
    "plt.savefig(path +'latent.png', dpi=600)\n",
    "\n",
    "\n",
    "# Plot training loss vs. epoch number\n",
    "plt.figure(figsize=(4.5, 4))\n",
    "const = min(train_loss)\n",
    "train_loss_adjusted = train_loss - const + 10.\n",
    "# val_loss_adjusted = val_loss - const + 10.\n",
    "plt.semilogy(train_loss_adjusted, label='train')\n",
    "# plt.semilogy(val_loss_adjusted, label='val')\n",
    "plt.xlabel(\"number of epochs\")\n",
    "# plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(path +'train_loss.png', dpi=600)\n",
    "plt.close()\n",
    "\n",
    "# Plot the training and validation loss vs. epoch number\n",
    "plt.figure(figsize=(4.5, 4))\n",
    "const = min(min(train_loss), min(valid_loss))\n",
    "train_loss_adjusted = train_loss - const + 10.\n",
    "valid_loss_adjusted = valid_loss - const + 10.\n",
    "plt.semilogy(train_loss_adjusted, label='train')\n",
    "plt.semilogy(valid_loss_adjusted, label='val')\n",
    "plt.xlabel(\"number of epochs\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(path +'loss.png', dpi=600)\n",
    "plt.close()\n",
    "\n",
    "# Plot the history of pi\n",
    "plt.figure(figsize=(4.5, 4))\n",
    "for i in range(K):\n",
    "    plt.plot(pi_history[:, i].detach().numpy(), label='$\\pi$' + str(i+1))\n",
    "plt.xlabel(\"number of epochs\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8863f884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(train_loss_list)\n",
    "# plt.plot(val_loss_list)\n",
    "plt.plot(rec_loss_list)\n",
    "plt.plot(reg_loss_list)\n",
    "plt.plot(entr_loss_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ee7942",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dic = {}\n",
    "results_dic['epochs'] = epoch_list\n",
    "results_dic['train_loss_epoch'] = train_loss_list\n",
    "results_dic['valid_loss_epoch'] = valid_loss_list\n",
    "results_dic['reconstruction_loss_epoch'] = rec_loss_list\n",
    "results_dic['regularization_loss_epoch'] = reg_loss_list\n",
    "results_dic['entropy_loss_epoch'] = entr_loss_list\n",
    "results_dic['mu_c'] = [mu_c.cpu().numpy().tolist() for mu in mu_c_hist]\n",
    "results_dic['logsigmasq_c'] = [logsig.cpu().numpy().tolist() for logsig in logsigmasq_c_hist]\n",
    "results_dic['means'] = [mu.cpu().numpy().tolist() for mu in means_hist]\n",
    "results_dic['pi'] = [pi.cpu().detach().numpy().tolist() for pi in pi_history]\n",
    "results_dic['gamma_c_train'] = [gamma.cpu().detach().numpy().tolist() for gamma in gamma_c_train_hist]\n",
    "results_dic['train_labels'] = train_labels.tolist()\n",
    "results_dic['gamma_c_val'] = [gamma.cpu().detach().numpy().tolist() for gamma in gamma_c_val_hist]\n",
    "results_dic['val_labels'] = valid_labels.tolist()\n",
    "\n",
    "with open(path + f'GMVAE_rocks_K1_Z4.json', 'w') as outfile:\n",
    "    json.dump(results_dic, outfile)\n",
    "    \n",
    "%xdel results_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79205b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "xmax = np.max(means_hist[0].numpy()[:,0])\n",
    "ymax = np.max(means_hist[0].numpy()[:,1])\n",
    "xmin = np.min(means_hist[0].numpy()[:,0])\n",
    "ymin = np.min(means_hist[0].numpy()[:,1])\n",
    "max_epoch = np.max(np.array(epoch_list))\n",
    "\n",
    "for i in range(len(means_hist)):\n",
    "    means = means_hist[i].numpy()\n",
    "    if np.max(means[:,0]) > xmax:\n",
    "        xmax = np.max(means[:,0])\n",
    "    if np.max(means[:,1]) > ymax:\n",
    "        ymax = np.max(means[:,1])\n",
    "    if np.min(means[:,0]) < xmin:\n",
    "        xmin = np.min(means[:,0])\n",
    "    if np.min(means[:,1]) < ymin:\n",
    "        ymin = np.min(means[:,1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab16348",
   "metadata": {},
   "outputs": [],
   "source": [
    "Writer = animation.writers['ffmpeg']\n",
    "writer = Writer(fps=20, metadata=dict(artist='Me'))\n",
    "\n",
    "fig, axs = plt.subplots(1,2,figsize=(13, 5))\n",
    "train_loss_list = np.array(train_loss_list)\n",
    "valid_loss_list = np.array(valid_loss_list)\n",
    "rec_loss_list = np.array(rec_loss_list)\n",
    "reg_loss_list = np.array(reg_loss_list)\n",
    "entr_loss_list = np.array(entr_loss_list)\n",
    "epoch_list = np.array(epoch_list)\n",
    "\n",
    "fig.suptitle(f'GMVAE | latent dim. = {latent_dim}, # clusters = {K}', fontsize=16)\n",
    "def animate(j):\n",
    "    print(j)\n",
    "    #Axis 1\n",
    "    means = means_hist[j]\n",
    "    mu_c = mu_c_hist[j]\n",
    "    sigmaq_c = np.exp(logsigmasq_c_hist[j].numpy())\n",
    "    axs[0].clear()\n",
    "    axs[1].clear()\n",
    "    for i in range(2):\n",
    "        means_i = means[train_labels == i]\n",
    "        axs[0].scatter(means_i[:, 0], means_i[:, 1], alpha=0.25, label=str(i))\n",
    "    for i in range(K):\n",
    "        axs[0].plot(mu_c[i, 0], mu_c[i, 1], 'x', markersize=12) #, label='$\\mu$' + str(i + 1))\n",
    "        c = axs[0].get_lines()[0].get_color()\n",
    "        ellipse = Ellipse((mu_c[i, 0], mu_c[i, 1]),\n",
    "        width=2*3*sigmaq_c[i, 0],\n",
    "        height=2*3*sigmaq_c[i, 1],\n",
    "        facecolor='None',\n",
    "        edgecolor = c,\n",
    "        linestyle = '--')\n",
    "        axs[0].add_patch(ellipse)\n",
    "        \n",
    "    axs[0].set_xlabel('$z_1$')\n",
    "    axs[0].set_ylabel('$z_2$')\n",
    "    axs[0].set_xlim([xmin, xmax])\n",
    "    axs[0].set_ylim([ymin, ymax])\n",
    "    axs[0].legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "    #Axis 2\n",
    "    axs[1].plot(epoch_list[0:j], train_loss_list[0:j] / train_loss[0],'k')\n",
    "    axs[1].plot(epoch_list[0:j], valid_loss_list[0:j] / valid_loss[0],'m')\n",
    "    axs[1].plot(epoch_list[0:j], rec_loss_list[0:j] / rec_loss[0],'r--')\n",
    "    axs[1].plot(epoch_list[0:j], reg_loss_list[0:j] / reg_loss[0],'g--')\n",
    "    axs[1].plot(epoch_list[0:j], entr_loss_list[0:j] / entr_loss[0],'b--')\n",
    "    axs[1].set_xlabel('$epoch #$')\n",
    "    axs[1].set_ylabel('$loss$')\n",
    "    axs[1].set_xlim([0, max_epoch])\n",
    "#     ax2.set_ylim([ymin, ymax])\n",
    "    axs[1].legend(['train loss', 'val loss', 'rec. loss', 'reg. loss', 'entropy loss'], loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea393021",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ani = matplotlib.animation.FuncAnimation(fig, animate, frames=len(epoch_list), repeat=False)\n",
    "ani.save(path + 'training_video.mp4', writer=writer, dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae638610",
   "metadata": {},
   "outputs": [],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c1ddaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
